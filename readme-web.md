# Web специфика

* [виды сетевых протоколов](#виды-сетевых-протоколов-)
* [Что такое `https` и зачем он нужен](#Что-такое-https-и-зачем-он-нужен-)
* [Понимание базовых аспектов функционирования сети - протоколы, `DNS`, и т.д.;](#Понимание-базовых-аспектов-функционирования-сети---протоколы,-DNS,-и-т.д.;-)
* [Что происходит при открытии вкладки браузера](#Что-происходит-при-открытии-вкладки-браузера-)
* [C каким серверным ПО приходилось работать?](#C-каким-серверным-ПО-приходилось-работать?-)
* [Что такое `Apache` и `mod_rewrite`?](#Что-такое-Apache-и-mod_rewrite?-)
* [`nginx`, его отличие от `apache`](#nginx,-его-отличие-от-apache-)
* [балансировка нагрузки на сервера приложений (`haproxy`)](#балансировка-нагрузки-на-сервера-приложений-(haproxy)-)
* [работы с системами очередей (`RabbitMQ`, `Kafka`)](#работы-с-системами-очередей-(RabbitMQ,-Kafka)-)
* [`CI` (`Continuous Integration`)](#CI-(Continuous-Integration)-)
* [Деплой](#Деплой-)
* [`Composer`](#Composer-)
* [`docker`](#docker-)
* [Стандарты написания кода](#Стандарты-написания-кода-)
* [Шаги по оптимизации сайта](#Шаги-по-оптимизации-сайта-)

# Web специфика

### виды сетевых протоколов [&uarr;](#devmap)

#### IP — Internet Protocol

Протокол передачи, который первым объединил отдельные компьютеры в единую сеть. Самый примитивный в этом списке. Он
является ненадёжным, т. е. не подтверждает доставку пакетов получателю и не контролирует целостность данных. По
протоколу IP передача данных осуществляется без установки соединения.

Основная задача этого протокола — маршрутизация датаграмм, т. е. определение пути следования данных по узлам сети.

Популярная версия на текущий момент — IPv4 с 32-битными адресами. Это значит, что в интернете могут хранится 4.29 млрд
адресов IPv4. Число большое, но не бесконечное. Поэтому существует версия IPv6, которая поможет решить проблему
переполнения адресов, ведь уникальных IPv6 будет 2 ^ 128 адресов (число с 38 знаками).

#### TCP/IP — Transmission Control Protocol/Internet Protocol

Это стек протоколов TCP и IP. Первый обеспечивает и контролирует надёжную передачу данных и следит за её целостностью.
Второй же отвечает за маршрутизацию для отправки данных. Протокол TCP часто используется более комплексными протоколами.
UDP — User Datagram Protocol

Протокол, обеспечивающий передачу данных без предварительного создания соединения между ними. Этот протокол является
ненадёжным. В нём пакеты могут не только не дойти, но и прийти не по порядку или вовсе продублироваться.

Основное преимущество UDP протокола заключается в скорости доставки данных. Именно поэтому чувствительные к сетевым
задержкам приложения часто используют этот тип передачи данных.

#### FTP — File Transfer Protocol

Протокол передачи файлов. Его использовали ещё в 1971 году — задолго до появления протокола IP. На текущий момент этим
протоколом пользуются при удалённом доступе к хостингам. FTP является надёжным протоколом, поэтому гарантирует передачу
данных.

Этот протокол работает по принципу клиент-серверной архитектуры. Пользователь проходит аутентификацию (хотя в отдельных
случаях может подключаться анонимно) и получает доступ к файловой системе сервера. DNS

Это не только система доменных имён (Domain Name System), но и протокол, без которого эта система не смогла бы работать.
Он позволяет клиентским компьютерам запрашивать у DNS-сервера IP-адрес какого-либо сайта, а также помогает обмениваться
базами данных между серверами DNS. В работе этого протокола также используются TCP и UDP.

#### HTTP — HyperText Transfer Protocol

Изначально протокол передачи HTML-документов. Сейчас же он используется для передачи произвольных данных в интернете. Он
является протоколом клиент-серверного взаимодействия без сохранения промежуточного состояния. В роли клиента чаще всего
выступает веб-браузер, хотя может быть и, например, поисковый робот. Для обмена информацией протокол HTTP в большинстве
случаев использует TCP/IP.

HTTP имеет расширение HTTPS, которое поддерживает шифрование. Данные в нём передаются поверх криптографического
протокола TLS.

#### NTP — Network Time Protocol

Не все протоколы передачи нужны для обмена классического вида информацией. NTP — протокол для синхронизации локальных
часов устройства со временем в сети. Он использует алгоритм Марзулло. Благодаря нему протокол выбирает более точный
источник времени. NTP работает поверх UDP — поэтому ему удаётся достигать большой скорости передачи данных. Протокол
достаточно устойчив к изменениям задержек в сети.

Последняя версия NTPv4 способна достигать точности 10мс в интернете и до 0,2мс в локальных сетях.

#### SSH — Secure SHell

Протокол для удалённого управления операционной системой с использованием TCP. В SSH шифруется весь трафик, причём с
возможностью выбора алгоритма шифрования. В основном это нужно для передачи паролей и другой важной информации.

Также SSH позволяет обрабатывать любые другие протоколы передачи. Это значит, что кроме удалённого управления
компьютером, через протокол можно пропускать любые файлы или даже аудио/видео поток.

SSH часто применяется при работе с хостингами, когда клиент может удалённо подключиться к серверу и работать уже оттуда.

### Что такое `https` и зачем он нужен [&uarr;](#devmap)

HTTPS (от англ. HyperText Transfer Protocol Secure) – расширение протокола HTTP, которое используется для шифрования и
безопасного обмена данными между пользователем и сайтом. Вся информация шифруется с помощью криптографических протоколов
TSL или его предшественника SSL. Википедия рулит! Если не уходить глубоко в технические подробности, то HTTPS шифрует
данные и не дает возможности их перехватить.

Принципом работы защищённого протокола HTTPS является обмен ключами шифрования. Прежде чем ответить на запрос от
браузера, сервер предъявляет ключ — SSL-certificate. Браузер проверяет подлинность ключа в Центре сертификации. Если
ключ «подошёл», браузер и сервер доверяют друг другу и договариваются о разовом шифре. Так происходит каждую сессию, то
есть каждый раз при обмене запросами и ответами. Вот таким хитрым способом и обеспечивается сохранность данных и
конфиденциальность при обмене информацией.

Как это работает? Как только Вы зашли на сайт, то Ваш браузер получает от сервера сертификат, в котором есть вся
информация о сайте, его владельце, кем выдан и еще много всего. Самое главное, Ваш браузер получает открытый ключ, по
которому он начнет шифровать все данные. На сервере стоит закрытый ключ, с помощью которого можно расшифровать всю
информацию.

Если кто-то захочет перехватить или получить конфиденциальные данные, то он сможет увидеть только набор с непонятных
символов, на расшифровку которых потребуется несколько лет. За это время сертификат устареет, и в итоге злоумышленник
ничего не получит.

#### Зачем нужен SSL-сертификат для сайта

    Чтобы сайт стал работать по протоколу безопасного соединения HТТPS, нужен SSL-сертификат. Это виртуальный документ, который содержит данные об организации, её владельце и подтверждает их существование. Позволяет узнать сервер и подтвердить безопасность сайта.

    Использование сертификата безопасности для сайта гарантирует:

        Подлинность ресурса, к которому обращается пользователь. Это повышает у посетителей уровень доверия.
        Целостность передаваемой информации. При транспортировке от сервера к браузеру данные не изменятся и не потеряются.
        Конфиденциальность. 256-разрядное шифрование исключает доступ злоумышленников к информации.

    Что дает SSL-сертификат для сайта кроме защиты данных? SSL-сертификат помогает в SEO-продвижении проекта — позволяет занять более высокую позицию в поисковой выдаче. Поисковые системы (Google, Яндекс и пр.) дорожат доверием аудитории и выше ранжируют сайты, которые работают через безопасное соединение.

### Понимание базовых аспектов функционирования сети - протоколы, `DNS`, и т.д.; [&uarr;](#devmap)

Интернет – это глобальная информационная система, которая:

· логически взаимосвязана пространством глобальных уникальных адресов, основанных на Интернет-протоколе (IP);

· способна поддерживать коммуникации с использованием семейства протокола управления передачей - TCP/IP или его
последующих расширений/преемников и/или других IP-совместимых протоколов;

· обеспечивает, использует или делает доступными на общественной или частной основе высокоуровневые услуги, надстроенные
над описанной здесь коммуникационной и иной связанной с ней инфраструктурой.

 

Инфраструктура Интернет:

1.магистральный уровень (система связанных высокоскоростных телекоммуникационных серверов).

2.уровень сетей и точек доступа (крупные телекоммуникационные сети), подключенных к магистрали.

3.уровень региональных и других сетей.

4.ISP – интернет-провайдеры.

5.пользователи.

К техническим ресурсам сети Интернет относятся компьютерные узлы, маршрутизаторы, шлюзы, каналы связи и др.

### Что происходит при открытии вкладки браузера [&uarr;](#devmap)

#### 1. Пользователь вводит в браузере адрес сайта

#### 2. Браузер начинает искать сервер

За работу любого сайта обычно отвечает один из миллионов серверов, подключенных к интернету. Адрес сервера — это
уникальный набор цифр, который называется IP-адресом. Например, для vc.ru— это сервер 85.119.149.83.

Поэтому первым делом браузеру нужно понять, какой IP-адрес у сервера, на котором находится сайт.

Такая информация хранится в распределенной системе серверов — DNS (Domain Name System). Система работает как общая
«контактная книга», хранящаяся на распределенных серверах и устройствах в интернете.

Однако перед тем, как обращаться к DNS, браузер пытается найти запись об IP-адресе сайта в ближайших местах, чтобы
сэкономить время:

    Сначала в своей истории подключений. Если пользователь уже посещал сайт, то в браузере могла сохраниться информация c IP-адресом сервера.
    В операционной системе. Не обнаружив информации у себя, браузер обращается к операционной системе, которая также могла сохранить у себя DNS-запись. Например, если подключение с сайтом устанавливалось через одно из установленных на компьютере приложений.
    В кэше роутера, который сохраняет информацию о последних соединениях, совершенных из локальной сети.

#### 3. Браузер отправляет запрос к DNS-серверам

Не обнаружив подходящих записей в кэше, браузер формирует запрос к DNS-серверам, расположенным в интернете.

Например, если нужно найти IP-адрес сайта mail.vc.ru, браузер спрашивает у ближайшего DNS-сервера «Какой IP-адрес у
сайта mail.vc.ru?».

Сервер может ответить: «Я не знаю про mail.vc.ru, но знаю сервер, который отвечает за vc.ru». Запрос переадресовывается
дальше, на сервер «выше», пока в итоге один из серверов не найдет ответ об IP-адресе для сайта.

#### 4. Браузер устанавливает соединение с сервером

Как только браузер узнал IP-адрес нужного сервера, он пытается установить с ним соединение. В большинстве случаев для
этого используется специальный протокол — TCP.

TCP — это набор правил, который описывает способы соединения между устройствами, форматы отправки запросов, действия в
случае потери данных и так далее.

Например, для установки соединения между браузером и сервером в стандарте TCP используется система «трёх рукопожатий».
Работает она так:

    Устройство пользователя отправляет специальный запрос на установку соединения с сервером — называется SYN-пакет.
    Сервер в ответ отправляет запрос с подтверждением получения SYN-пакета — называется SYN/ACK-пакет.
    В конце устройство пользователя при получении SYN/ACK-пакета отправляет пакет с подтверждением — ACK-пакет. В этот момент соединение считается установленным.

#### 5. Браузер отправляет HTTP-запрос, чтобы получить контент сайта

После установки соединения браузер отправляет специальный запрос, в котором просит сервер отправить данные для
отображения страницы. В этом запросе содержится информация о самом браузере, временные файлы, требования к соединению и
так далее.

Задача браузера — как можно подробнее объяснить серверу, какая именно информация ему нужна.

В общении браузера и сервера выделяют два типа запросов. GET-запрос используется для получения данных с сервера —
например, отобразить картинку, текст или видео. POST-запрос — используется для отправки данных из браузера на сервер,
например, когда пользователь отправляет сообщение, картинку или загружает файл.

    Почти все сайты обмениваются информацией с сервером в зашифрованном формате — с помощью HTTPS-протокола. 
    В отличие от HTTP-протокола, в HTTPS используется шифрование, а безопасность подключения подтверждается специальным сертификатом.

#### 6. Сервер обрабатывает запрос

Сервер получил запрос от браузера с подробным описанием того, что ему требуется. Теперь ему нужно обработать этот
запрос. Этой задачей занимается специальное серверное программное обеспечение — например, nginx или Apache. Чаще всего
такие программы принято называть веб-серверами.

Веб-сервер в свою очередь перенаправляет запрос на дальнейшую обработку к программе-обработчику — например, PHP, Ruby
или ASP.NET. Программа внимательно изучает содержимое запроса — например, понимает, в каком формате нужно отправить
ответ и какие именно файлы нужны. И собирает ответ.

#### 7. Сервер отправляет ответ браузеру

Когда ответ сформирован, он отправляется веб-сервером обратно браузеру. В ответе как правило содержится контент для
отображения веб-страницы, информация о типе сжатия данных, способах кэширования, файлы cookie, которые нужно записать и
так далее.

    👉 Чтобы обмен данными был быстрым, браузер и сервер обмениваются сразу множеством небольших пакетов данных — как правило, в пределах 8 КБ. 
    Все пакеты имеют специальные номера, которые помогают отслеживать последовательность отправки и получения данных.

#### 8. Браузер обрабатывает полученный ответ и «рисует» веб-страницу

Браузер распаковывает полученный ответ и постепенно начинает отображать полученный контент на экране пользователя — этот
процесс называется рендерингом.

Сначала браузер загружает только основную структуру HTML-страницы. Затем последовательно проверяет все теги и отправляет
дополнительные GET-запросы для получения с сервера различных элементов — картинки, файлы, скрипты, таблицы стилей и так
далее. Поэтому по мере загрузки страницы браузер и сервер продолжают обмениваться между собой информацией.

Параллельно с этим на компьютер как правило сохраняются статичные файлы пользователя — чтобы при следующем посещении не
загружать их заново и быстрее отобразить пользователю содержимое страницы.

Как только рендеринг завершен — пользователю отобразится полностью загруженная страница сайта.

### C каким серверным ПО приходилось работать? [&uarr;](#devmap)

Веб-сервер - Apache, Nginx. Веб-сервер — это специальная программа, которая принимает запросы пользователей,
обрабатывает их и отправляет ответ обратно по протоколу прикладного уровня HTTP.

Интерпретатор языка программирования

СУБД — система управления базами данных: MySQL, PostgreSQL, MS SQL, Oracle, Redis, MongoDB и т.д.

Поисковые системы — ElasticSearch / Sphinx — позволяют осуществлять поиск и фильтрацию быстрее, нежели это возможно с
использованием реляционных СУБД. Kibana - для визуализации данных, полученных из Elasticsearch - это в рамках настройки
хранилища для логов на базе Elasticsearch, Logstash и Kibana, которое называют ELK Stack. Sphinx - движок
полнотекстового поиска.

Elasticsearch (далее ES) — масштабируемая поисковая система, которую также можно отнести к нереляционным (noSQL) базам
данных. В основном используется для полнотекстового поиска с фильтрами и анализаторами.

Кеширующие сервера — системы, «запоминающие» результат обработки запросов и использующие эти данные при повторных
обращениях для ускорения генерации страниц — Memcached и Redis.

Софт для резервного копирования — бэкапы должны создаваться регулярно и автоматически, а также хранится не на том же
сервере, где расположены «боевые данные».

Ускорители исполнения программного кода. Служат для повышения производительности, часто используемые ускорители для PHP:
APC, eAccellerator, XCache.

Мониторинг и оповещения — системы, собирающие важные метрики производительности системы и сообщающие о проблемах.

### Что такое `Apache` и `mod_rewrite`? [&uarr;](#devmap)

Apache – это свободное программное обеспечение для размещения веб-сервера. Он хорошо показывает себя в работе с
масштабными проектами.

mod_rewrite — это модуль для веб-сервера Apache, предназначенный для преобразования URL-ов. Модуль использует в своей
работе правила, которые могут быть описаны как в конфигурации сервера (httpd.conf), так и в файлах .htaccess
непосредственно в файловой структуре Вашего сайта. Правила описываются в виде регулярных выражений

### `nginx`, его отличие от `apache` [&uarr;](#devmap)

#### Краткий обзор Apache

Apache был разработан для доставки веб-контента, доступ к которому осуществляется через Интернет. Он известен тем, что
играл ключевую роль в начальном росте интернета. Apache - это программное обеспечение с открытым исходным кодом,
разработанное и поддерживаемое открытым сообществом разработчиков и работающее в самых разных операционных системах.
Архитектура включает в себя ядро Apache и модули. Основной компонент предоставляет базовую серверную функцию, поэтому он
принимает соединения и управляет параллелизмом. Различные модули соответствуют различным функциям, которые выполняются
по каждому запросу. Конкретное развертывание Apache может быть сконфигурировано для включения различных модулей, таких
как функции безопасности, управление динамическим контентом или для базовой обработки HTTP-запросов.

Модель «один сервер делает все» стала ключом к раннему успеху Apache. Однако по мере увеличения уровня трафика и
увеличения количества веб-страниц и ограничения производительности настройка Apache на работу с реальным трафиком
усложнялась.

#### Краткий обзор Nginx

Nginx был разработан специально для устранения ограничений производительности веб-серверов Apache. Производительность и
масштабируемость Nginx обусловлены архитектурой, управляемой событиями. Он значительно отличается от подхода Apache. В
Nginx каждый рабочий процесс может одновременно обрабатывать тысячи HTTP-соединений. Следовательно, Nginx - это
легковесная, масштабируемая и высокопроизводительная реализация. Эта архитектура делает обработку больших и
флуктуирующих нагрузок на данные гораздо более предсказуемой с точки зрения использования ОЗУ, использования ЦП и
задержки.

Nginx также имеет богатый набор функций и может выполнять различные роли сервера:

    Обратный прокси-сервер для протоколов HTTP, HTTPS, SMTP, POP3 и IMAP
    Балансировщик нагрузки и HTTP-кеш
    Интерфейсный прокси для Apache и других веб-серверов, сочетающий гибкость Apache с хорошей производительностью статического контента Nginx

#### Apache против Nginx: сравнение их богатых наборов функций

#### Простота

Разрабатывать и обновлять приложения на Apache очень просто. Модель «одно соединение на процесс» позволяет очень легко
вставлять модули в любой точке логики веб-обслуживания. Разработчики могут добавлять код таким образом, что в случае
сбоев будет затронут только рабочий процесс, выполняющий код. Обработка всех других соединений будет продолжаться без
помех.

Nginx, с другой стороны, имеет сложную архитектуру, поэтому разработка модулей не легка. Разработчики модулей Nginx
должны быть очень осторожны, чтобы создавать эффективный и точный код, без сбоев, и соответствующим образом
взаимодействовать со сложным ядром, управляемым событиями, чтобы избежать блокирования операций.

#### Производительность

Производительность измеряется тем, как сервер доставляет большие объемы контента в браузер клиента, и это важный фактор.
Контент может быть статическим или динамическим. Давайте посмотрим статистику по этому вопросу. Статический контент

Nginx работает в 2,5 раза быстрее, чем Apache, согласно тесту производительности, выполняемому до 1000 одновременных
подключений. Другой тест с 512 одновременными подключениями показал, что Nginx примерно в два раза быстрее и потребляет
меньше памяти. Несомненно, Nginx имеет преимущество перед Apache со статическим контентом. Поэтому, если вам нужно
обслуживать одновременный статический контент, Nginx является предпочтительным выбором.

#### Динамический контент

Результаты тестов Speedemy показали, что для динамического контента производительность серверов Apache и Nginx была
одинаковой. Вероятная причина этого заключается в том, что почти все время обработки запросов расходуется в среде
выполнения PHP, а не в основной части веб-сервера. Среда выполнения PHP довольно похожа для обоих веб-серверов.

Apache также может обрабатывать динамический контент, встраивая процессор языка, подобного PHP, в каждый из его рабочих
экземпляров. Это позволяет ему выполнять динамический контент на самом веб-сервере, не полагаясь на внешние компоненты.
Эти динамические процессоры могут быть включены с помощью динамически загружаемых модулей.

Nginx не имеет возможности обрабатывать динамический контент изначально. Чтобы обрабатывать PHP и другие запросы на
динамический контент, Nginx должен перейти на внешний процессор для выполнения и дождаться отправки визуализированного
контента. Однако этот метод также имеет некоторые преимущества. Поскольку динамический интерпретатор не встроен в
рабочий процесс, его издержки будут присутствовать только для динамического содержимого.

#### Поддержка ОС

Apache работает во всех операционных системах, таких как UNIX, Linux или BSD, и полностью поддерживает Microsoft
Windows. Nginx также работает на нескольких современных Unix-подобных системах и поддерживает Windows, но его
производительность в Windows не так стабильна, как на платформах UNIX. Безопасность

И Apache, и Nginx являются безопасными веб-серверами. Apache Security Team существует, чтобы предоставить помощь и
советы проектам Apache по вопросам безопасности и координировать обработку уязвимостей безопасности. Важно правильно
настроить серверы и знать, что делает каждый параметр в настройках.

#### Гибкость

Веб-серверы могут быть настроены путем добавления модулей. Apache долго загружал динамические модули, поэтому все модули
Apache поддерживают это.

Nginx Plus (Nginx Plus - это программный балансировщик нагрузки, веб-сервер и кэш контента, построенный на основе
открытого исходного кода Nginx) также использует модульную архитектуру. Новые функции и возможности могут быть добавлены
с программными модулями, которые могут быть подключены к работающему экземпляру Nginx Plus по требованию. Динамические
модули добавляют в Nginx Plus такие функции, как геолокация пользователей по IP-адресу, изменение размеров изображений и
встраивание сценариев Lua в модель обработки событий Nginx Plus. Модули создаются как Nginx, Inc., так и сторонними
разработчиками.

Большинство необходимых функциональных возможностей основного модуля (например, прокси, кэширование, распределение
нагрузки) поддерживаются обоими веб-серверами.

#### Поддержка и документация

Важным моментом, который следует учитывать, является доступная справка и поддержка веб-серверов среди прочего
программного обеспечения. Поскольку Apache был популярен так долго, поддержка сервера довольно распространена
повсеместно. Для главного сервера и для основанных на задачах сценариев, связанных с подключением Apache к другому
программному обеспечению, имеется большая библиотека документации первого и стороннего производителя.

Наряду с документацией многие инструменты и веб-проекты содержат инструменты для начальной загрузки в среде Apache. Это
может быть включено в сами проекты или в пакеты, поддерживаемые отделом упаковки вашего дистрибутива.

Apache, как правило, получает большую поддержку от сторонних проектов просто из-за своей доли рынка и продолжительности
времени, в течение которого он был доступен.

В прошлом для Nginx было трудно найти исчерпывающую англоязычную документацию из-за того, что большая часть ранней
разработки и документации была на русском языке. Однако на сегодняшний день документация заполнена, и на сайте Nginx
имеется множество ресурсов для администрирования и доступной документации от третьих лиц.

#### Nginx и Apache - Совместная работа

Для многих приложений Nginx и Apache хорошо дополняют друг друга. Очень распространенным начальным шаблоном является
развертывание программного обеспечения Nginx с открытым исходным кодом в качестве прокси-сервера (или Nginx Plus в
качестве платформы доставки приложений) перед веб-приложением на основе Apache. Nginx выполняет тяжелую работу,
связанную с HTTP - обслуживает статические файлы, кэширует содержимое и разряжает медленные HTTP-соединения - так что
сервер Apache может выполнять код приложения в безопасной и защищенной среде.

### балансировка нагрузки на сервера приложений (`haproxy`) [&uarr;](#devmap)

HAProxy, или High Availability Proxy, является программным балансировщиком нагрузки TCP/HTTP. Он распределяет рабочую
нагрузку по серверам для обеспечения максимальной производительности и оптимизации использования ресурсов. HAProxy
поддерживает гибко настраиваемые методы проверки доступности, обработки отказов и восстановления после них.

HAProxy устанавливается на отдельный сервер, который принимает клиентские запросы и перенаправлять их на веб-сервера
Nginx.

### работы с системами очередей (`RabbitMQ`, `Kafka`) [&uarr;](#devmap)

#### Apache Kafka

Apache Kafka – это распределенная платформа потоковой передачи событий с открытым исходным кодом, обеспечивающая высокую
пропускную способность. Написанная на Java и Scala, Кафка представляет собой шину сообщений системы Pub/Sub,
ориентированную на потоки и воспроизведение данных с высокой интенсивностью. Кафка не полагается на очередь, а добавляет
сообщения в журнал и оставляет их там до достижения предела хранения или тех пор, пока консьюмер не прочитает эти
сообщения.

Apache Kafka лучше всего подходит для потоковой передачи от А к Б без сложной маршрутизации, но с максимальной
пропускной способностью. Инструмент отлично справляется с event sourcing, потоковой обработкой и моделированием
изменений в системе в качестве последовательности событий. Кафку также можно использовать для обработки данных при
многоэтапной конвейерной обработке.

Кафка станет отличным решением, если вам нужен фреймворк для хранения, чтения, повторного чтения и анализа потоковых
данных. Ее сильная сторона – обработка и анализ данных в реальном времени. Инструмент идеально подходит для постоянного
хранения сообщений или для регулярно проверяемых систем.

#### RabbitMQ

RabbitMQ – это распределенный брокер сообщений с открытым исходным кодом, который обеспечивает эффективную доставку
сообщений в рамках сложных сценариев маршрутизации. Этот инструмент называется «распределенным», потому что обычно
работает как кластер узлов, где очереди распределяются (реплицируются) по узлам для обеспечения высокой доступности и
отказоустойчивости.

По умолчанию в RabbitMQ используется протокол AMQP 0.9.1, также существуют расширения для поддержки дополнительных
протоколов: AMQP 1.0, HTTP, STOMP и MQTT. RabbitMQ официально поддерживает Elixir, Go, Java, JavaScript, .NET, PHP,
Python, Ruby, Objective-C, Spring и Swift. Пользователям доступны различные инструменты разработки и клиенты,
использующие расширения сообщества.

Разработчики используют RabbitMQ для обработки высокопроизводительных и надежных фоновых заданий, а также для интеграции
и взаимодействия внутри приложений и между ними. Инструмент применяется для выполнения сложной маршрутизации к
консьюмерам и интеграции нескольких приложений и служб с нетривиальной логикой маршрутизации.

RabbitMQ идеально подходит для веб-серверов, которым требуется быстрый запрос-ответ. Этот инструмент распределяет
нагрузку между рабочими приложениями при высокой нагрузке (более 20 000 сообщений в секунду) и может обрабатывать
фоновые задания или длительные задачи, такие как преобразование PDF, сканирование файлов или масштабирование
изображений.

#### Основные отличия Apache Kafka и RabbitMQ

    Поток данных. RabbitMQ использует определенный ограниченный поток данных. Продюсер создает и отправляет сообщения, а консьюмер их принимает. Apache Kafka использует неограниченный поток данных, при этом пары «ключ-значение» непрерывно передаются в назначенную тему.

    Использование данных. RabbitMQ отлично подходит для запросов пользователей и транзакционных данных, таких как создание и размещение заказов. Кафка лучше справляется с операционными данными, такими как технологические процессы, статистика аудита и сбора данных, активность системы.

    Обмен сообщениями. RabbitMQ отправляет пользователям сообщения, которые удаляются из очереди после их обработки и подтверждения. Кафка – это журнал. Он использует непрерывные цепочки сообщений, которые сохраняются в очереди до истечения срока хранения.

    Модель проектирования. RabbitMQ использует модель умный брокер/тупой консьюмер. Брокер последовательно доставляет сообщения консьюмерам и отслеживает их статус. Apache Kafka использует модель тупого брокера/умного консьюмера. Этот инструмент не отслеживает сообщения, которые прочитал каждый пользователь. Кафка запоминает только непрочитанные сообщения, сохраняя их в течение установленного периода времени. Консьюмеры должны самостоятельно следить за своей позицией в каждом журнале.

    Топология. RabbitMQ использует топологию обмена очереди: сообщения отправляются на обмен, откуда затем рассылаются в различные привязки очередей для использования консьюмерами. Кафка использует топологию Publish/Subscribe, отправляя сообщения через поток в соответствующие топики, которые затем потребляются пользователями в разных авторизованных группах.

### `CI` (`Continuous Integration`) [&uarr;](#devmap)

CI/CD означает «Continuous Integration/Continuous Delivery» — то есть «непрерывная интеграция/непрерывная доставка». Это
подход к разработке, при котором задачи сборки, публикации, тестирования продукта полностью или частично
автоматизированы. Очень часто автоматизация интегрирована в бизнес-процессы продуктовой команды или компании, но
практики CI/CD прекрасно могут быть внедрены и в проекты, в которых участвует только один разработчик.

Существует большое количество инструментов для сборки кода и публикации его для пользователей. У каждого свои
особенности и тонкости использования. Но есть и конкурирующие между собой инструменты. Среди конкурирующих платформ
стоит говорить о GitLab CI/CD, Bitbucket Pipelines, Jenkins, Netlify, JetBrains TeamCity, GitHub Actions и прочие.

Здесь я кратко и по возможности без огрехов опишу процесс работы системы с высоты птичьего полёта:

    разработчик отпраляет коммит в репозиторий, создаёт merge request через сайт, или ещё каким-либо образом явно или неявно запускает пайплайн,
    из конфигурации выбираются все задачи, условия которых позволяют их запустить в данном контексте,
    задачи организуются в соответствии со своими этапами,
    этапы по очереди выполняются — т.е. параллельно выполняются все задачи этого этапа,
    если этап завершается неудачей (т.е. завершается неудачей хотя бы одна из задач этапа) — пайплайн останавливается (почти всегда),
    если все этапы завершены успешно, пайплайн считается успешно прошедшим.

Таким образом, имеем:

    пайплайн — набор задач, организованных в этапы, в котором можно собрать, протестировать, упаковать код, развернуть готовую сборку в облачный сервис, и пр.,
    этап (stage) — единица организации пайплайна, содержит 1+ задачу,
    задача (job) — единица работы в пайплайне. Состоит из скрипта (обязательно), условий запуска, настроек публикации/кеширования артефактов и много другого.

Соответственно, задача при настройке CI/CD сводится к тому, чтобы создать набор задач, реализующих все необходимые
действия для сборки, тестирования и публикации кода и артефактов.

### Деплой [&uarr;](#devmap)

Деплой (deploy) — это развертывание и запуск веб-приложения или сайта в его рабочей среде, то есть на сервере или
хостинге. Разработчик загружает приложение, написанное на локальном компьютере, в специальное пространство, из которого
оно доступно в интернете.

Популярные - Jenkins или GitLab CI

О DevOps и его практиках

    DevOps, грубо говоря, регламентирует «завод» и «конвейер» на нём.

    Одной из практик DevOps является CI/CD/CDP. Эта практика описывает шаги «конвейера».

    CI (Continuous Integration, непрерывная интеграция) – начальная стадия «конвейера» по сборке кода и загрузке собранного ПО в среду разработки.

    CD (Continuous delivery, непрерывная поставка) – является продолжением CI. В этой практике производится автоматизированное развертывание на тестовую среду продукта и разнообразные тесты над ним.

    CDP (Continuous Deployment, непрерывное развертывание) – поставка результатов работы CI и CD практик в промышленную среду.

Jenkins или GitLab, в свою очередь, может реализовать CI/CD/CDP на практике.

### `Composer` [&uarr;](#devmap)

Composer — менеджер пакетов для PHP.

Composer, менеджер зависимостей для PHP, был выпущен около 10 лет назад, а недавно опубликовали новую версию, 2.0. За
эти годы Composer получил множество новых функций и не отставал от стандартов PHP. Вторая версия совместима со старыми
проектами, но привнесет еще несколько замечательных новых функций.

Список улучшений:

Ускорение и оптимизация

    В этом релизе была улучшена производительность. Теперь он не учитывает уже установленные пакеты, в результате обновление проходит намного быстрее. Также улучшили работу с памятью и процессором.

    Команда установки стала умнее. Теперь она не изменяет папку vendor до тех пор, пока не гарантирует, что все пакеты установлены. Это позволяет избежать потери времени на их удаление в случае ошибок во время процесса.

    Одной из лучших функций, для меня, стала параллельная загрузка, которая теперь поддерживается из коробки, и нам не нужно устанавливать дополнительные пакеты, как hirak/prestissimo, чтобы это работало.

Поддержка оффлайн

    Composer представил возможность использовать его в оффлайн режиме. Это может быть интересно для бенчмарков или при возникновении проблем с подключением к интернету

Поддержка --dry-run для “require” и “remove”

    Эта опция уже была доступна при обновлении пакетов (composer update --dry-run. Она позволяет нам увидеть, что произойдет при запуске команды, просто отображая данные в терминале, без реальных изменений в вашем проекте или папке vendor.

    Composer 2.* дает возможность использовать опцию с composer require и composer remove что делает нашу жизнь проще

Предотвращение проблем при работе от root

    При выполнении команд от пользователя root теперь требуется подтверждение, чтобы предотвратить наши ошибки.

Канонические репозитории

    Эта функция решает определенную проблему, с которой сталкиваются несколько разработчиков при использовании одного и того же пакета в разных репозиториях. Composer 1.0 следовал определенному порядку при установке/обновлении своих пакетов. Он начал искать пакеты в своем списке репозиториев до тех пор, пока пакет не будет найден (также последняя версия).

    Иногда это было не совсем ожидаемое поведение при работе с различными версиями пакетов в других репозиториях (используемых одним и тем же проектом). Представьте себе, что иногда вы хотите загрузить пакет из своего частного репозитория, а не из packagist, в котором есть пакет с тем же именем.

    По умолчанию, в composer 2.x, все репозитории являются каноническими. Composer 1.x рассматривал все репозитории как неканонические, и для того, чтобы поменять поведение вручную, вы можете сделать

    {
        "repositories": [
            {
                "type": "composer",
                "url": "https://example.org",
                "canonical": false
            }
        ]
    }

Игнорировать определенное требование платформы

    Если по какой-то причине вы хотите проигнорировать какое-либо определенное требование платформы, вы можете просто запустить команду: composer install --ignore-platform-req php

    Она пропустит требование для PHP или конкретной версии. Если вы собираетесь игнорировать все требования, вам следует использовать команду, уже доступную в предыдущих версиях --ignore-platform-reqs

### `docker` [&uarr;](#devmap)

Docker — это технология, которая позволяет создавать и использовать приложения в «родном» окружении. В основе Docker
лежит идея: если приложение работает у вас, то оно должно работать где угодно. Способ этого добиться очень простой —
нужно упаковать настройки окружения вместе с приложением.

Docker чаще всего применяется для развёртывания серверных приложений, но может использоваться и в мире фронтенда.

Docker Compose — это инструмент для запуска мультиконтейнерного приложения, которое не зависит от платформы и содержит
все необходимые для работы технологии и библиотеки. Конфигурация такого приложения записывается в одном текстовом файле
в формате YAML. Запускается приложение одной командой в терминале.

В файле compose.yaml могут быть следующие элементы верхнего уровня:

— version (скоро исключат): информация о версии формата файла конфигурации; — services (обязательный): список всех
контейнеров, которые нужно будет запустить; — networks: список подсетей Docker Network, которые объединяют группы
контейнеров в виртуальную локальную сеть (она может быть доступна из внешнего мира); — volumes: список томов, которые
будут доступны контейнерам, описанным в файле конфигурации; — configs: список параметров, которые позволяют запускать
контейнеры в различных режимах, не собирая их заново; — secrets: список чувствительных с точки зрения безопасности
параметров (то же, что и configs, но специального назначения).

Обычно жизненный цикл контейнера состоит из следующей последовательности состояний:

    Создание контейнера
    Работа контейнера
    Приостановка контейнера
    Возобновление работы контейнера
    Запуск контейнера
    Остановка контейнера
    Перезапуск контейнера
    Принудительная остановка контейнера
    Удаление контейнера

### Важные службы

Движок Docker Engine — приложение для управления объектами Docker. Оно включает в себя три компонента:

    -  интерфейс (Docker API);
    -  консольный клиент (Docker CLI) - в терминал вводят команды, начинающиеся с ключевого слова docker, обращаясь к клиенту. Затем клиент использует API Docker для отправки команд демону Docker.
    -  сервер (Docker Daemon) — это сервер Docker, который ожидает запросов к API Docker. Демон Docker управляет образами, контейнерами, сетями и томами.

Ваш компьютер называется Docker Host. Все операции, которые мы выполняем в интерфейсе или через консоль, выполняются
сервером через API движка.

Docker Desktop — пакет приложений с графическим интерфейсом, включающий специальную виртуальную машину для работы с
движком, визуальный интерфейс (Dashboard), консольный клиент, инструменты для работы с реестром Docker Hub и пр.

### Объекты Docker

    Образ (Docker Image) — прототип будущего контейнера, содержащий операционную систему, приложение или проект для сборки приложения. Образы состоят из слоёв. Каждый новый слой — это надстройка над предыдущим. Слои должны надстраиваться поверх базового образа, формируя новый. Например, базовым образом может быть образ операционной системы.

    Контейнер (Docker Container) — уже собранное и запущенное приложение в изолированном окружении, которое формируется послойно, в соответствии с образом. Каждый новый слой расширяет функциональность предыдущего, формируя стек используемых инструментов, платформ и настроек системных служб. Файловая система контейнера тоже стековая (Union File Systems). Каталоги и файлы отдельного слоя образа накладываются друг на друга, образуя единое целое.

    Том (Docker Volume) — папка, которую можно подключить (говорят «примонтировать») к контейнерам. Папка может быть связана с конкретной папкой на вашем компьютере, а может быть как бы сетевой для контейнеров на вашем компьютере. Тома необходимы для хранения файлов конфигурации, критических с точки зрения безопасности, файлов баз данных, файлов, которые нельзя удалять после окончания работы приложения.

    Сеть (Docker Network) — виртуальная локальная сеть, которая позволяет совместно использовать несколько запущенных контейнеров и соединять запущенный контейнер с вашим компьютером. В основном вы будете использовать три режима работы сетевой инфраструктуры Docker:

    bridge — когда контейнеры могут взаимодействовать между собой как веб-сервер и база данных.
    host — для доступа к локальному сетевому окружению на вашем компьютере.
    none — сеть для контейнеров полностью отключена.

### Инструменты

Docker Hub (реестр) — официальный реестр образов.

Опубликованные образы хранятся в Docker Hub. Существуют и другие публичные реестры образов:

    Google Cloud Container Registry;
    Azure Container Registry;
    IBM Cloud Container Registry;
    Oracle Cloud Infrastructure Container Registry;
    Yandex Container Registry.

Репозиторий Docker

    Репозиторием Docker (Docker Repository) называют набор образов Docker, обладающих одинаковыми именами и разными тегами. Теги — это идентификаторы образов.

    Обычно в репозиториях хранятся разные версии одних и тех же образов. Например, Python — это имя популярнейшего официального репозитория Docker на хабе Docker. А вот Python:3.7-slim — это версия образа с тегом 3.7-slim в репозитории Python. В реестр можно отправить как целый репозиторий, так и отдельный образ.

Docker CLI — консольный клиент, позволяющий управлять Docker через интерфейс командной строки.

Консольный клиент содержит команды для управления объектами Docker. Список основных команд:

    docker ps;
    docker run;
    docker image;
    docker container;
    docker volume.

### Как пользоваться

Ключи командного интерфейса Docker CLI хорошо проработаны и похожи на консольные команды в bash. Например,
дополнительный ключ prune позволяет удалять неиспользуемые объекты. Ключ rm служит для удаления, а ключ ls для просмотра
объектов. Объекты Docker в обязательном порядке имеют уникальное имя. Если вы не именуете объект специально, то имя
объекта формируется с помощью хэш-функции. Если вы попытаетесь создать объект одного и того же типа с уже использованным
именем, в этом вам будет отказано.

Мониторинг запущенных контейнеров

    docker ps — просмотр запущенных контейнеров.
    docker ps -a — ключ -a выводит и запущенные, и остановленные контейнеры.
    docker ps -s — ключ -s выводит дисковое пространство, используемое каждым запущенным контейнером.
    docker ps -f name=hello — ключ -f фильтрует список контейнеров по имени, например, hello.

### Запуск контейнеров

Для запуска контейнера, который доступен локально или на Docker Hub, выполните команду:

    docker run --name test -i -t hello 
    или
    docker exec -it тут_имя_контейнера bash

Ключ --name используется для установки имени запущенного контейнера. Ключи -i и -t указывают, что для запуска контейнера
будет использоваться стандартный поток ввода и терминал TTY соответственно. Для того чтобы при запуске контейнера
примонтировать том, который будет связан с папкой на вашем компьютере, а потом получить доступ к контейнеру через
терминал, выполните команду:

    docker run -t -i --mount type=bind,src=/data,dst=/data hello bash

### Управление образами

Вы можете получить список всех доступных локально образов с помощью команды:

    docker image ls

Ключи prune, rm действуют обычным способом, позволяя удалить неиспользуемые или конкретные образы соответственно. Для
работы с реестром необходимо использовать следующие команды:

    docker image pull hello — загрузка образа с именем hello из реестра;
    docker image push hello — отправка образа с именем hello в реестр;
    docker image inspect hello — полная информация о контейнере hello;
    docker image build — собрать контейнер из текущей папки с учётом Dockerfile.

### Периодическая чистка данных Докера

    docker container prune
    docker image prune
    docker volume prune
    docker network prune

### скачать все образы докера

    docker pull docker.ru/php/php-apache -a
    docker pull docker.ru/php/php-fpm -a

### Управление томами

    docker volume ls — вывод всех томов.
    docker volume ls -f name=hello — вывод всех томов с фильтрацией по имени, например, hello.
    docker volume create hello — создание нового тома, например, hello.
    docker volume inspect hello — исчерпывающая информация о томе.

### Образы Docker

Контейнер Docker — это образ Docker, вызванный к жизни. Это — самодостаточная операционная система, в которой имеется
только самое необходимое и код приложения.

Образы Docker являются результатом процесса их сборки, а контейнеры Docker — это выполняющиеся образы. В самом сердце
Docker находятся файлы Dockerfile. Подобные файлы сообщают Docker о том, как собирать образы, на основе которых
создаются контейнеры - инструкции, при сборке образа, обрабатываются сверху вниз.

При запуске команды docker build для создания нового образа подразумевается, что Dockerfile находится в текущей рабочей
директории.

Слои в итоговом образе создают только инструкции FROM, RUN, COPY, и ADD. Другие инструкции что-то настраивают, описывают
метаданные, или сообщают Docker о том, что во время выполнения контейнера нужно что-то сделать, например — открыть
какой-то порт или выполнить какую-то команду.

Дюжина инструкций Dockerfile

    FROM — задаёт базовый (родительский) образ.
    LABEL — описывает метаданные. Например — сведения о том, кто создал и поддерживает образ.
    ENV — устанавливает постоянные переменные среды.
    RUN — выполняет команду и создаёт слой образа. Используется для установки в контейнер пакетов.
    COPY — копирует в контейнер файлы и папки.
    ADD — копирует файлы и папки в контейнер, может распаковывать локальные .tar-файлы.
    CMD — описывает команду с аргументами, которую нужно выполнить когда контейнер будет запущен. Аргументы могут быть переопределены при запуске контейнера. В файле может присутствовать лишь одна инструкция CMD.
    WORKDIR — задаёт рабочую директорию для следующей инструкции.
    ARG — задаёт переменные для передачи Docker во время сборки образа.
    ENTRYPOINT — предоставляет команду с аргументами для вызова во время выполнения контейнера. Аргументы не переопределяются.
    EXPOSE — указывает на необходимость открыть порт.
    VOLUME — создаёт точку монтирования для работы с постоянным хранилищем.

Файл .dockerignore

    Вот что даёт тому, кто занимается созданием образов Docker, применение файлов .dockerignore:

    1) Это позволяет исключать из состава образа файлы, содержащие секретные сведения наподобие логинов и паролей.
    2) Это позволяет уменьшить размер образа. Чем меньше в образе файлов — тем меньше будет его размер и тем быстрее с ним можно будет работать.
    3) Это даёт возможность уменьшить число поводов для признания недействительным кэша при сборке похожих образов. Например, если при повторной сборке образа меняются некие служебные файлы проекта, наподобие файлов с журналами, из-за чего данные, хранящиеся в кэше, по сути, необоснованно признаются недействительными, это замедляет сборку образов.

Несколько советов, касающихся эффективного использования кэша Docker:

    1) Используйте всегда, когда это возможно, официальные образы в качестве базовых образов. Официальные образы регулярно обновляются, они безопаснее неофициальных образов.
    
    2) Для того чтобы собирать как можно более компактные образы, пользуйтесь базовыми образами, основанными на Alpine Linux.
    
    3) Если вы пользуетесь apt, комбинируйте в одной инструкции RUN команды apt-get update и apt-get install. Кроме того, объединяйте в одну инструкцию команды установки пакетов. Перечисляйте пакеты в алфавитном порядке на нескольких строках, разделяя список символами \. Например, это может выглядеть так:

    RUN apt-get update && apt-get install -y \
        package-one \
        package-two \
        package-three
    && rm -rf /var/lib/apt/lists/*


    Этот метод позволяет сократить число слоёв, которые должны быть добавлены в образ, и помогает поддерживать код файла в приличном виде.

    4) Включайте конструкцию вида && rm -rf /var/lib/apt/lists/* в конец инструкции RUN, используемой для установки пакетов. Это позволит очистить кэш apt и приведёт к тому, что он не будет сохраняться в слое, сформированном командой RUN.
    
    5) Разумно пользуйтесь возможностями кэширования, размещая в Dockerfile команды, вероятность изменения которых высока, ближе к концу файла.
    
    6) Пользуйтесь файлом .dockerignore.
    
    7) Взгляните на dive — отличный инструмент для исследования образов Docker, который помогает в деле уменьшения их размеров.

Создание образов

    Вот команда, которая позволяет собирать образы Docker:

    docker image build -t my_repo/my_image:my_tag .

    Флаг -t — это сокращение для --tag. Он указывает Docker на то, что создаваемому образу надо назначить предоставленный в команде тег. В данном случае это my_tag.

    Точка в конце команды указывает на то, что образ надо собрать с использованием файла Dockerfile, находящегося в текущей рабочей директории.

    После того, как образ собран, его можно отправить в удалённый реестр. Благодаря этому им смогут воспользоваться другие люди, его можно будет загрузить и запустить на другом компьютере. Предположим, вы хотите использовать Docker Hub. 

    После того, как вы зарегистрируетесь на Docker Hub, вам нужно войти в систему:

    docker login

    После входа в систему можно будет отправлять образы в реестр:

    docker image push my_repo/my_image:my_tag

### Стандарты написания кода [&uarr;](#devmap)

### Восемь общих правил

Существуют правила, которые подойдут для написания кода на любом языке программирования. Только следование им уже
повысит качество вашего кода.

    Придумывайте понятные и читаемые названия. Избегайте русских слов в латинской транскрипции. Только английские слова, обозначающие суть.
    Делайте отступы на каждом уровне и отделяйте логические блоки пустой строкой.
    Сокращайте вложенность кода и убирайте дублирование.
    Контролируйте длину. Рекомендуем для функций не более 20 строк, для метода не более 50 строк, для класса не более 300 строк, для файла — не более 1000 строк. Также ограничивайте длину одной строки до видимого значения на экране. Мягкое ограничение составляет 120 символов.
    Комментируйте и документируйте код. Это позволит зафиксировать всю необходимую информацию.
    Используйте рефакторинг. Следуйте принципу «рефакторинг — раньше и рефакторинг — чаще». Советуем также прочитать книгу «Рефакторинг. Улучшение проекта существующего кода» Мартина Фаулера.
    Работайте в системе контроля версий, например, Git. Это бесплатно и удобно. Обучиться работать в ней можно за 11 занятий на видеокурсе «Git. Быстрый старт».
    Изучайте Open Source код. Вы сможете увидеть, как пишут ведущие разработчики и воспользоваться лучшими практиками в программировании

### Статический анализ кода

Часто можно сказать, насколько код программы корректен, даже не запуская её. Процесс исследования исходного кода без
запуска называют статическим анализом или линтингом, а программу, которая это делает — статическим анализатором или
линтером.

Линтер — это программа, которая разбирает исходный код на стандартизированные кусочки, а потом даёт эти кусочки на
проверку специальным плагинам. Плагин получает разобранный участок кода и проверяет его на корректность по ряду правил,
которые определены в этом плагине.

Самый популярный линтер для JavaScript — это ESLint. Он находит участки кода, которые могут потенциально привести к
ошибкам, и сообщает об этом.

Чтобы воспользоваться ESLint, нужно установить его через менеджер зависимостей в папке проекта.

npm install --save-dev eslint

После установки нужно инициализировать конфигурационный файл .eslintrc.json.

npx eslint --init

В созданный файл можно добавлять правила, по которым линтер будет работать. Обычно используют стандартную конфигурацию,
поверх которой добавляют правила, подходящие для конкретного проекта.

{ // ...
"extends": "eslint:recommended", // ... }

Теперь можно добавить в package.json новый скрипт, который будет запускать статический анализ.

{ // ...
"scripts": {
"lint": "eslint ./**/*.js"
} // ... }

После запуска линтера командой npm run lint, в консоли появится результат его работы.

На самом деле, статически проанализировать можно почти любой язык программирования. Поэтому, при разработке
веб-приложений часто не останавливаются на использовании ESLint, а добавляют ещё Stylelint — линтер для стилей. Он умеет
работать не только с CSS, но и почти с любым языком описания стилей, например, CSS-in-JS, SCSS или Stylus.

Автоматический запуск

    Не хочется нагружать голову разработчика необходимостью запускать линтер самостоятельно, и это автоматизируют:

    - запускают линтер на серверах и показывают результат программисту, этот подход называют CI, он широко применяется в индустрии;
    - добавляют автоматический вызов линтера при создании нового коммита в репозитории;
    - интегрируют статический анализ в среду разработки, так можно получать рекомендации прямо во время написания кода и сразу на них реагировать.

### PSR

PSR (PHP Standards Recommendations) — описывает общие концепции, которые уже были проверены и отработаны.

Список PSR стандартов расширяется новыми, а сами стандарты делятся на категории:

    - Автозагрузка, 
    - Интерфейсы, 
    - HTTP
    - Стиль кодирования

    каждому из которых присваивается определенный статус:
    Принят, Устаревший, Черновик и Заброшенный.

Стиль кодирования:

    Цель следующих PSR стандартов уменьшить когнитивное искажение при чтении кода от разных авторов.

     - PSR-1: Basic Coding Standard
     - PSR-2 — Coding Style Guide Устарел
     - PSR-12: Extended Coding Style Guide 

Описанные выше спецификации достаточно объемные, поэтому мы рассмотрим только базовые из PSR-1:

    - Использование только тэгов <?php и <?=
    - Только UTF-8 без BOM для php кода
    - Не стоит мешать разный функционал в одном файле (1 файл = 1 класс)
    - Пространство имен и классы должны следовать [PSR-0, PSR-4]
    - Классы объявляются в `StudlyCase`
    - Константы объявляются в ТАКОМ_ВИДЕ
    - Методы объявляются в `camelCase`

На самом деле, нет смысла помнить про кажный пункт о переносе скобки, пробеле, табе и т.п., так как существует различный
функционал, который позволяет автоматически проверить и отформатировать кодовую базу по стандарту PSR-2/PSR-12:

    - Ручной режим: можно использовать reformat code в phpStorm.
    - Более продвинутый вариант: использовать какой-нибуть кодснифер, например PHP CS Fixer (часто используется в CI, чтобы не принимать коммиты с неотформатированным кодом).

### Код-ревью

Код-ревью — это область, где особенно ярко проявляются софт-скиллы инженеров. Провести хорошее код-ревью сложнее, чем
написать хороший код.

    Отправка изменений на код-ревью происходит через пул-реквесты. Для прохождения код-ревью нужно получить одобрение одного или нескольких коллег. Способ выбора коллег для проведения ревью зависит от процессов внутри компании.

    Пул-реквест (PR) — это предложение слить изменения в ветке разработчика с другой веткой. Иногда их называют мёрж-реквестами (MR).

Conventional comments

Conventional comments предлагает формат, где сообщение описывается как:

    <label> [decorations]: <subject>
    [discussion]

    label - тип комментария;
    subject - основная мысль комментария;
    decorations (опционально) - дополнительные лэйблы для комментария. Они окружены скобками;
    discussion (опционально) - здесь содержатся подтверждающие заявления, контекст, рассуждения и все остальное, чтобы помочь сообщить "почему" и "последующие шаги" для разрешения замечания;

Например:

    question (non-blocking): На этом этапе имеет значение, какой поток выиграл?
    Может быть, чтобы предотвратить состояние гонки, мы должны продолжать зацикливаться, пока все они не выиграют?

Настоятельно рекомендуется использовать следующие лэйблы:

    praise - «Похвала» подчёркивает что-то положительное. Попробуйте оставить хотя бы один такой комментарий. Не оставляйте ложных похвал (которые на самом деле могут нанести вред).

    nitpick - «Придирки» - это небольшие, но необходимые изменения. Придирчивые комментарии значительно помогают направить внимание читателя на комментарии, требующие большего внимания.

    suggestion - «Предложения» предоставляют способы по совершенствованию в определённой теме. Важно быть предельно ясным в том, что предлагается и почему именно это улучшение. Рассмотрите возможность использовать блокирующие и не блокирующие декорации для последующего информирования о ваших намерениях.

    issue - «Проблемы» высвечивают конкретные трудности рассматриваемого вопроса. Если вы не уверены, существует проблема или нет - рассмотрите возможность оставить question.

    question - «Вопросы» допустимы, если у вас есть потенциальная проблема, но не уверены уместна она или нет. Обращение к автору с просьбой о разъяснении или расследовании может привести к быстрому урегулированию этого вопроса.
    
    thought - «Мысли» представляют собой идею, которая всплыла в процессе ревью. Эти замечания по своей природе не блокируют, но они чрезвычайно ценны и могут привести к более целенаправленным предложениям и возможностям наставничества.

    chore - «Рутинная работа» - это небольшие задачи которые необходимо выполнить до того как пулреквест (или другая форма ревью) «официально» будут приняты. Обычно в таких комментариях упоминаются какие-то общие процессы. Постарайтесь оставить ссылку в описании на процесс, чтобы автор мог понять как именно выполнять рутинную работу.

Декорации дают дополнительный контекст для комментария:

    (non-blocking) - комментарий с такой декорацией не должен препятствовать принятию рассматриваемого пулреквеста. Это полезно для команд, которые рассматривают блокирование комментариев по умолчанию.

    (blocking) - комментарий с такой декорацией должен препятствовать принятию рассматриваемого вопроса до тех пор, пока он не будет решён. Это полезно для команд, которые считают, что комментарии не блокируются по умолчанию.

    (if-minor) - эта декорация даёт автору некоторую свободу действий, которая заключается в том, что он может разрешить комментарий только в том случае, если изменения окажутся незначительными или тривиальными.

### Шаги по оптимизации сайта [&uarr;](#devmap)

Бэкенд и запросы к бд:

    - анализируем лог sql запросов 
    - Убираем запросы в цикле
    - В запрашиваемых данных из БД в массиве select оставляем только нужные.
    - Если время запроса превышает 0.001 секунду - оптимизируем запрос, думаем над созданием индексов
    - Проверяем, настроено ли кэширование и параметры, от которого оно зависит.

Конфигурация и производительность сервера:

    - Версия Mysql должна быть не ниже выше 5.7, версия PHP - не ниже 7.0
    - Желательно наличие акселератора PHP (OPcache, XCache, APC и другого). Лучше всего OPcache

Фронтенд - работа со скриптами, стилями, статикой, изображениями и пр:

    Проверяем сайт через:

    - https://developers.google.com/speed/pagespeed/insights/ - оценка для мобильных устройств и декстопа должна находится в зелёной зоне
    - https://tools.pingdom.com/ - вес страницы не должен превышать 2-3 Mb
    - В консоли Chrome в панели audits показатели должны быть выше 60%

    Что должно быть реализовано:

    - Статическая информация должна кэшироваться браузером (проверить настройки в .htaccess)
    - Для загрузки картинок, не входящих в первый экран, обязательно использовать lazy-load. Это так же касается вторых, третьих и тд картинок на слайдерах
    Картинки должны быть оптимизированы для веба и отресайзены на нужные размеры
    - Использовать для картинок тэг picture
    - Минификация / обфускация js скриптов
    - Количество подгружаемых на странице js-скриптов должно быть ограничего, т.к. стандартно браузеры могут загружать файлы не более чем в 6-10 потоков с одного хоста. Т.е. работать будет быстрее, если собрать несколько мелких js в один большой, чем загружать 40 маленьких отдельно. 
    - Сторонние стандартные библиотеки лучше подгружать извне, т.к. существует вероятность, что браузер пользователя уже их выкачал и закэшировал
